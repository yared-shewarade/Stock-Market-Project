{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "4449d42c-21d5-49b9-af27-184a3e3bf1f4"
    }
   },
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import datetime\n",
    "import dateutil\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# import APIs\n",
    "from Keys.NYTAPI import nyt_api\n",
    "from Keys.NewsAPI import news_api\n",
    "from Keys.AlphaAPI import alpha_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make api_keys global vars so that functions can use them\n",
    "def set_api_global():\n",
    "    global nyt_api\n",
    "    global news_api\n",
    "    global alpha_api\n",
    "\n",
    "set_api_global()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic & Stock_Quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Topic = \"Apple\"\n",
    "Stock_Quote = \"AAPL\"\n",
    "\n",
    "# make the key_word global\n",
    "def set_topicstockquote_global():\n",
    "    global Topic\n",
    "    global Stock_Quote\n",
    "\n",
    "set_topicstockquote_global()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "73444a3f-8c76-4d5d-a6d6-7205277f6a4a"
    }
   },
   "source": [
    "# Stock Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Define a function that returns a stock dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_data(stock_quote, stock_dates):\n",
    "    stock_url = \"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=\"+stock_quote+\"&apikey=\"+alpha_api\n",
    "    open_prices = []\n",
    "    volumes = []\n",
    "    dates_output = []\n",
    "    \n",
    "    data = requests.get(stock_url).json()\n",
    "    \n",
    "    for stock_date in tqdm(stock_dates):\n",
    "        # There are holidays and weekends\n",
    "        try:\n",
    "            open_prices.append(data[\"Time Series (Daily)\"][stock_date][\"1. open\"])\n",
    "            volumes.append(data[\"Time Series (Daily)\"][stock_date][\"5. volume\"])\n",
    "            if stock_date in data[\"Time Series (Daily)\"].keys():\n",
    "                dates_output.append(stock_date)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    stock_df = pd.DataFrame({\"Date\": dates_output, \n",
    "                             stock_quote+\" Open Price\": pd.to_numeric(open_prices), \n",
    "                             stock_quote+\" Volume\": pd.to_numeric(volumes)\n",
    "                            })\n",
    "    return stock_df, dates_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "e93d91a1-0791-4abd-8694-7f8a82299e74"
    }
   },
   "outputs": [],
   "source": [
    "# set stock_dates\n",
    "stock_dates = []\n",
    "\n",
    "# decide the start date\n",
    "start_date = datetime.date(2018,6,1)\n",
    "number_of_days = 91\n",
    "\n",
    "for i in range(number_of_days):\n",
    "    stock_date = start_date + datetime.timedelta(i)\n",
    "    stock_dates.append(stock_date.isoformat())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Get the stock dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stock_df, stock_dates_output = get_stock_data(Stock_Quote, stock_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_df.to_csv(os.path.join(\".\", Topic, Stock_Quote+\"_\"+\"open price & volume.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b45da7a9-21f2-43a3-905e-56f097af14e9"
    }
   },
   "source": [
    "## 1) Extract data from New York Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a function that transfer the ISO formatted string back to datetime\n",
    "def getDataTimeFromISO(iso):\n",
    "    d = dateutil.parser.parse(iso)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getDataTimeFromISO(stock_dates_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the day_lag variable. -1 means the news yesterday may determines the price today.\n",
    "day_lag = -1\n",
    "# change the date\n",
    "bd = getDataTimeFromISO(stock_dates_output[0]).date()+datetime.timedelta(day_lag)\n",
    "# the params works in a way that does not include the end date. Therefore we need one more day from the end date\n",
    "ed = getDataTimeFromISO(stock_dates_output[-1]).date()+datetime.timedelta(day_lag+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "21b7e7c7-8f47-4fd9-9464-255b117d5ac2"
    }
   },
   "outputs": [],
   "source": [
    "bd = bd.isoformat()\n",
    "ed = ed.isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "8784529d-2093-44d4-9bbc-b586f78d754a"
    }
   },
   "outputs": [],
   "source": [
    "begin_date = bd[:4] + bd[5:7] + bd[8:10]\n",
    "end_date = ed[:4] + ed[5:7] + ed[8:10]\n",
    "print(begin_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make bd, ed global\n",
    "def set_date_global():\n",
    "    global bd\n",
    "    global ed\n",
    "    global day_lag\n",
    "\n",
    "set_date_global()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "fe19293b-bfca-42bf-a283-f6de4bc87c22"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# prepare variables\n",
    "# make sure we can loop through all the articles we get\n",
    "n = 500\n",
    "pages = range(n)\n",
    "nyt_snippet = []\n",
    "nyt_pub_date = []\n",
    "\n",
    "# urls\n",
    "nyt_base_url = \"https://api.nytimes.com/svc/search/v2/articlesearch.json?\"\n",
    "\n",
    "# get data from urls\n",
    "for page in tqdm(pages):\n",
    "    params = {\n",
    "        \"api-key\": nyt_api,\n",
    "        \"q\": Topic,\n",
    "        \"begin_date\": begin_date,\n",
    "        \"end_date\": end_date,\n",
    "        \"sort\": \"newest\",\n",
    "        \"fl\": [\"snippet\",\"pub_date\"],\n",
    "        \"page\": page\n",
    "    }\n",
    "    # pause to avoid being classified as spam\n",
    "    # time.sleep(0.2)\n",
    "    \n",
    "    try: \n",
    "        nyt_data = requests.get(nyt_base_url, params=params).json()\n",
    "        # loop through 10 articles on each page\n",
    "        for i in range(10):\n",
    "            nyt_snippet.append(nyt_data[\"response\"][\"docs\"][i][\"snippet\"])\n",
    "            interm_date = nyt_data[\"response\"][\"docs\"][i][\"pub_date\"]\n",
    "            nyt_pub_date.append(interm_date[:4]+interm_date[5:7]+interm_date[8:10])\n",
    "   \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Save The New York Times data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt_news_df = pd.DataFrame({\"Date\": nyt_pub_date, \"Snippet\": nyt_snippet})\n",
    "nyt_news_df.to_csv(os.path.join(\".\", Topic, \"New York Times.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Extract Data from News API - WSJ, FOX, CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### note the pages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newsAPI(news_input):\n",
    "    base_url = \"https://newsapi.org/v2/everything\"\n",
    "    description = []\n",
    "    pub_date = []\n",
    "    pageSize = 100\n",
    "    pages = range(20)\n",
    "    \n",
    "    if news_input == \"WSJ\":\n",
    "        news_source = \"the-wall-street-journal\"\n",
    "    elif news_input == \"CNN\":\n",
    "        news_source = \"cnn\"\n",
    "    elif news_input == \"FOX\":\n",
    "        news_source = \"fox-news\"\n",
    "    \n",
    "    for page in tqdm(pages):\n",
    "        params = {\n",
    "            \"q\": Topic,\n",
    "            \"sources\": news_source,\n",
    "            \"apiKey\": news_api,\n",
    "            \"from\": bd,\n",
    "            # due to the different params functions, change the end date here to match the dates in New York Times\n",
    "            \"to\": (getDataTimeFromISO(ed)+datetime.timedelta(-1)).date().isoformat(),\n",
    "            \"pageSize\": pageSize,\n",
    "            \"page\": page,\n",
    "            \"sortBy\": \"publishedAt\"\n",
    "        }\n",
    "        # pause to avoid being classified as spam\n",
    "        time.sleep(0.2)\n",
    "        \n",
    "        try:\n",
    "            data = requests.get(base_url, params=params).json()\n",
    "            # loop through each article on each page\n",
    "            for i in range(pageSize):\n",
    "                description.append(data[\"articles\"][i][\"description\"])\n",
    "                pub_date.append(data[\"articles\"][i][\"publishedAt\"][:10])\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return description, pub_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsj_description, wsj_pub_date = newsAPI(\"WSJ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnn_description, cnn_pub_date = newsAPI(\"CNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Save Data from News API - WSJ, CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please Note: FOX has been taken out because it does not have much data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsj_news_df = pd.DataFrame({\"Date\": wsj_pub_date, \"Description\": wsj_description})\n",
    "wsj_news_df.to_csv(os.path.join(\".\", Topic, \"WSJ.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_news_df = pd.DataFrame({\"Date\": cnn_pub_date, \"Description\": cnn_description})\n",
    "cnn_news_df.to_csv(os.path.join(\".\", Topic, \"CNN.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "9785a933-4b9d-4168-9c24-92444309dab9"
    }
   },
   "source": [
    "# Vader Sentiment Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Get vader scores from news data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "87a00b1b-c509-42e1-8f9a-3c52243fd515"
    }
   },
   "outputs": [],
   "source": [
    "# define a function to recycle the code\n",
    "def vaderSentimentScoreCalculator(dates, sentences):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    vader_scores = []\n",
    "    news_dates = []\n",
    "    for date, sentence in zip(dates, sentences):\n",
    "        try: \n",
    "            vs = analyzer.polarity_scores(sentence)\n",
    "            vader_scores.append(vs['compound'])\n",
    "            news_dates.append(date)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return news_dates, vader_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt_dates, nyt_vaderscores = vaderSentimentScoreCalculator(nyt_pub_date, nyt_snippet)\n",
    "wsj_dates, wsj_vaderscores = vaderSentimentScoreCalculator(wsj_pub_date, wsj_description)\n",
    "cnn_dates, cnn_vaderscores = vaderSentimentScoreCalculator(cnn_pub_date, cnn_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "1cdfb901-2ae5-4077-b618-1c8a08fda3c0"
    }
   },
   "source": [
    "## 2) Set up dataframe for vader score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def news_to_vaderscore(news_source, pub_date, vadercores):\n",
    "    \n",
    "    news_dates = []\n",
    "    \n",
    "    for d in pub_date:\n",
    "        d = getDataTimeFromISO(d).date() - datetime.timedelta(day_lag)\n",
    "        d = d.isoformat()\n",
    "        news_dates.append(d)\n",
    "    \n",
    "    news_df = pd.DataFrame({\"Date\": news_dates, news_source+\" VS (Day_Lag=\"+str(day_lag)+\")\": vadercores})\n",
    "    \n",
    "    grouped_news_df = news_df.groupby(\"Date\")\n",
    "    \n",
    "    adjusted_news_df = pd.DataFrame({\n",
    "        \"Date\": grouped_news_df.count().index,\n",
    "        news_source+\" VS (Day_Lag=\"+str(day_lag)+\")\": grouped_news_df[news_source+\" VS (Day_Lag=\"+str(day_lag)+\")\"].mean()\n",
    "        })\n",
    "    \n",
    "    # format the vader score\n",
    "    adjusted_news_df[news_source+\" VS (Day_Lag=\"+str(day_lag)+\")\"] = adjusted_news_df[news_source+\" VS (Day_Lag=\"+str(day_lag)+\")\"].map(\"{:.4f}\".format)\n",
    "    \n",
    "    # convert vader score to numeric\n",
    "    adjusted_news_df[news_source+\" VS (Day_Lag=\"+str(day_lag)+\")\"] = pd.to_numeric(adjusted_news_df[news_source+\" VS (Day_Lag=\"+str(day_lag)+\")\"])\n",
    "    \n",
    "    return adjusted_news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt_df = news_to_vaderscore(\"NYT\", nyt_dates, nyt_vaderscores)\n",
    "wsj_df = news_to_vaderscore(\"WSJ\", wsj_dates, wsj_vaderscores)\n",
    "cnn_df = news_to_vaderscore(\"CNN\", cnn_dates, cnn_vaderscores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt_df.to_csv(os.path.join(\".\", Topic, \"nyt_vs.csv\"))\n",
    "wsj_df.to_csv(os.path.join(\".\", Topic, \"wsj_vs.csv\"))\n",
    "cnn_df.to_csv(os.path.join(\".\", Topic, \"cnn_vs.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge stock dataframes and vader score dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt_wsj_df = nyt_df.merge(wsj_df, how=\"inner\", on=\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt_wsj_cnn_df = nyt_wsj_df.merge(cnn_df, how=\"inner\", on=\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_news_df = stock_df.merge(nyt_wsj_cnn_df, how=\"inner\", on=\"Date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_news_df.to_csv(os.path.join(\".\", Topic, Topic+\"_\"+\"final.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "price = stock_news_df.iloc[:,1]\n",
    "volume = stock_news_df.iloc[:,2]\n",
    "vs_all = stock_news_df.iloc[:,3:6]\n",
    "x_axis = stock_news_df.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_news_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Price vs VaderScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig =plt.figure(figsize=(16,12))    # creating figure object\n",
    "ax = fig.add_subplot(212)           # adding axes on this figure\n",
    "\n",
    "# instantiate a second axes that shares the same x-axis\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "# ploting Stock price and Vader Score on the same axis\n",
    "\n",
    "price.plot(ax=ax, label=Stock_Quote+\" Price\",color=\"b\", marker=\"o\", markersize=10, lw=5,ls='--', alpha=1)\n",
    "vs_all.plot(ax=ax2, label=\"Vader Score\",color=[\"r\",\"g\",\"y\"],markersize=10, lw=4,ls='-',alpha=0.5)\n",
    "\n",
    "\n",
    "# designing labile and ticks\n",
    "\n",
    "ax.set_ylabel(Stock_Quote +\"Price\",fontdict = {\"fontsize\" : 22, \"fontweight\": \"bold\"})\n",
    "ax.set_xlabel(\"Date\",fontdict = {\"fontsize\" : 22, \"fontweight\": \"bold\"})\n",
    "ax2.set_ylabel(\"Vader Score\",fontdict = {\"fontsize\" : 22, \"fontweight\": \"bold\"})\n",
    "ax.set_xticklabels(x_axis, fontdict = {\"fontsize\" : 12, \"fontweight\": \"bold\"}, rotation = 75)\n",
    "ax.set_xticks(np.arange(0, len(stock_news_df.iloc[:,0])))\n",
    "\n",
    "# setting a title\n",
    "\n",
    "ax.set_title(Stock_Quote+\" Price vs Vader Score\", fontdict = {\"fontsize\" : 28, \"fontweight\": \"bold\"})\n",
    "ax.legend(numpoints = 2, frameon = True, markerscale = 1.5, edgecolor = 'blue', fontsize = '12', framealpha = 1, loc=\"upper left\")\n",
    "ax.grid()\n",
    "\n",
    "# save and show fig\n",
    "fig1 = plt.gcf()\n",
    "fig1.savefig(os.path.join(\".\", Topic, Topic+\"_\"+\"Price vs VaderScore\"), dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Volume vs VaderScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig =plt.figure(figsize=(16,12))    # creating figure object\n",
    "ax = fig.add_subplot(212)           # adding axes on this figure\n",
    "\n",
    "# instantiate a second axes that shares the same x-axis\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "# ploting Stock price and Vader Score on the same axis\n",
    "\n",
    "volume.plot(ax=ax, label=Stock_Quote+\" Volume\",color=\"b\", marker=\"o\", markersize=10, lw=5,ls='--', alpha=1)\n",
    "vs_all.plot(ax=ax2, label=\"Vader Score\",color=[\"r\",\"g\",\"y\"],markersize=10, lw=4,ls='-',alpha=0.5)\n",
    "\n",
    "\n",
    "# designing labile and ticks\n",
    "\n",
    "ax.set_ylabel(Stock_Quote +\"Price\",fontdict = {\"fontsize\" : 22, \"fontweight\": \"bold\"})\n",
    "ax.set_xlabel(\"Date\",fontdict = {\"fontsize\" : 22, \"fontweight\": \"bold\"})\n",
    "ax2.set_ylabel(\"Vader Score\",fontdict = {\"fontsize\" : 22, \"fontweight\": \"bold\"})\n",
    "ax.set_xticklabels(x_axis, fontdict = {\"fontsize\" : 12, \"fontweight\": \"bold\"}, rotation = 75)\n",
    "ax.set_xticks(np.arange(0, len(stock_news_df.iloc[:,0])))\n",
    "\n",
    "# setting a title\n",
    "\n",
    "ax.set_title(Stock_Quote+\" Volume vs Vader Score\", fontdict = {\"fontsize\" : 28, \"fontweight\": \"bold\"})\n",
    "ax.legend(numpoints = 2, frameon = True, markerscale = 1.5, edgecolor = 'blue', fontsize = '12', framealpha = 1, loc=\"upper left\")\n",
    "ax.grid()\n",
    "\n",
    "# save and show fig\n",
    "fig2 = plt.gcf()\n",
    "fig2.savefig(os.path.join(\".\", Topic, Topic+\"_\"+\"Volume vs VaderScore\"), dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PyData]",
   "language": "python",
   "name": "conda-env-PyData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
